{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tnFYDve6LhG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"~/Thesis/Data/train.csv\")\n",
    "ratings = pd.read_csv('~/Data/clean_rating4.csv').drop([\"id\"], axis = 1)\n",
    "\n",
    "idx_to_animes = list(set(ratings['anime_id'].tolist()))\n",
    "idx_to_users = list(set(ratings['user_id'].tolist()))\n",
    "anime_to_idx = {anime: idx for idx, anime in enumerate(idx_to_animes)}\n",
    "user_to_idx = {user: idx for idx, user in enumerate(idx_to_users)}\n",
    "num_users, num_animes = len(idx_to_users), len(idx_to_animes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = train_df.values.tolist()\n",
    "train_users = list(set(train_df.user))\n",
    "user_item_dic = defaultdict(list)\n",
    "\n",
    "train_data = []\n",
    "for d in train_data_raw:\n",
    "    train_data.append([user_to_idx[d[0]], anime_to_idx[d[1]]])\n",
    "    user_item_dic[user_to_idx[d[0]]].append(anime_to_idx[d[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRDataset(Data.Dataset):\n",
    "    def __init__(self, data, num_item, num_ng, dic):\n",
    "        super(BPRDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.num_ng = num_ng\n",
    "        self.dic = dic\n",
    "        self.num_item = num_item\n",
    "        \n",
    "    def select_ng(self):\n",
    "        self.new_data = []\n",
    "        for idx, d in enumerate(self.data):\n",
    "            if not idx % 100000: print(idx)\n",
    "            ng_num = 0\n",
    "            while ng_num < self.num_ng:\n",
    "                item = np.random.randint(self.num_item)   \n",
    "                if item not in self.dic[d[0]]:\n",
    "                    self.new_data.append([d[0], d[1], item])\n",
    "                    ng_num += 1\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return self.num_ng * len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user = self.new_data[idx][0]\n",
    "        item_i = self.new_data[idx][1]\n",
    "        item_j = self.new_data[idx][2]\n",
    "        \n",
    "        return user, item_i, item_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR(nn.Module):\n",
    "    def __init__(self, num_users, num_animes, num_hidden):\n",
    "        super(BPR, self).__init__()\n",
    "        self.user_embed = nn.Embedding(num_users, num_hidden)\n",
    "        self.anime_embed = nn.Embedding(num_animes, num_hidden)\n",
    "        \n",
    "        nn.init.normal_(self.user_embed.weight, std = 0.01)\n",
    "        nn.init.normal_(self.anime_embed.weight, std = 0.01)\n",
    "        \n",
    "    def forward(self, user, anime_i, anime_j):\n",
    "        point_i = torch.mm(self.user_embed(user), self.anime_embed(anime_i).permute(1, 0)).sum(dim = -1)\n",
    "        point_j = torch.mm(self.user_embed(user), self.anime_embed(anime_j).permute(1, 0)).sum(dim = -1)\n",
    "        \n",
    "        return point_i, point_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "torch.Size([10000]) torch.Size([10000]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "train_dataset = BPRDataset(train_data, num_animes, 5, user_item_dic)\n",
    "train_dataset.select_ng()\n",
    "data_iter = Data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "for x, y, z in data_iter:\n",
    "    print(x.shape, y.shape, z.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, lr, num_epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"train on \", device)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum, n = 0, 0\n",
    "        for user, item_i, item_j in data_iter:\n",
    "            user = user.to(device)\n",
    "            item_i = item_i.to(device)\n",
    "            item_j = item_j.to(device)\n",
    "            \n",
    "            point_i, point_j = net(user, item_i, item_j)\n",
    "#             print(point_i.shape, point_j.shape)\n",
    "            loss = - (point_i - point_j).sigmoid().log().sum()\n",
    "            for name, v in net.named_parameters():\n",
    "                loss += torch.mm(torch.t(v), v).sum()\n",
    "#             print(loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            l_sum += loss.item()\n",
    "            n += 1\n",
    "            \n",
    "        print(epoch + 1, l_sum / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on  cuda\n",
      "1 30.648999848172195\n",
      "2 0.0007467528257032308\n",
      "3 0.000663203525019216\n",
      "4 0.0007771549425718985\n",
      "5 0.002070564635652908\n",
      "6 0.00456850003264617\n",
      "7 0.012098252700507567\n",
      "8 0.029975381198820178\n",
      "9 0.062191725159302734\n",
      "10 0.10858001306161776\n",
      "11 0.17155738844466878\n",
      "12 0.21775755772005506\n",
      "13 0.27114282481108537\n",
      "14 0.3023840341721553\n",
      "15 0.3083470133525548\n",
      "16 0.31004916497202584\n",
      "17 0.2990703439210361\n",
      "18 0.2916379367275407\n",
      "19 0.27460222861414574\n",
      "20 0.2738083366745849\n",
      "21 0.2924947790501319\n",
      "22 0.2946966233343723\n",
      "23 0.2866062854163085\n",
      "24 0.2890528145818192\n",
      "25 0.2763640492863416\n",
      "26 0.2603687576321892\n",
      "27 0.2843275551612561\n",
      "28 0.28042879442301133\n",
      "29 0.26883271361117833\n",
      "30 0.26601723223124085\n"
     ]
    }
   ],
   "source": [
    "bpr_net = BPR(num_users, num_animes, 100)\n",
    "train(bpr_net, 0.001, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bpr_net.state_dict(), \"BPR2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"~/Thesis/Data/test.csv\")\n",
    "users = list(set(test_df.user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_net = BPR(4701, 9775, 100).cuda()\n",
    "bpr_net.load_state_dict(torch.load(\"BPR2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(k, ranklist, testlist):\n",
    "    if not testlist: return 0\n",
    "    idcg_k, dcg_k = 0, 0\n",
    "    if len(testlist) < k:\n",
    "        k = len(testlist)\n",
    "    for i in range(k):\n",
    "        idcg_k += 1 / math.log(i + 2, 2)\n",
    "        \n",
    "    s = set(testlist)\n",
    "    hits = [idx for idx, val in enumerate(ranklist) if val in s]\n",
    "    count = len(hits)\n",
    "    \n",
    "    for i in range(count):\n",
    "        dcg_k += 1 / math.log(hits[i] + 2, 2)\n",
    "        \n",
    "    return float(dcg_k / idcg_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(net, bound):\n",
    "    precision = []\n",
    "    for user in users:\n",
    "        animes = test_df[test_df.user == user].anime.tolist()\n",
    "        user_input = torch.LongTensor([user_to_idx[user] for _ in range(len(animes))]).cuda()\n",
    "        anime_input = torch.LongTensor([anime_to_idx[i] for i in animes]).cuda()\n",
    "        \n",
    "#         print(user_input, anime_input)\n",
    "        point_i, point_j = net(user_input, anime_input, anime_input)\n",
    "#         print(point_i.shape)\n",
    "        _, idx = torch.topk(point_i, 5)\n",
    "        \n",
    "        target = test_df[(test_df.user == user) & (test_df.rating > bound)].anime.tolist()\n",
    "        idx = [animes[i] for i in idx]\n",
    "        \n",
    "#         precision.append(len(set(idx) & set(target)) / len(idx))\n",
    "        precision.append(ndcg(10, idx, target))\n",
    "        \n",
    "    return np.mean(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026816075910204686\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for k in range(9, 10):\n",
    "    result.append(metric(bpr_net, k))\n",
    "    print(result[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9069559668155712, 0.7984258668368431, 0.6593065305254201, 0.44981918740693466, 0.2057009146990002, 0.05207402680280791, 0.011231652839821315, 0.005360561582641991, 0.0043395022335673255]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNXgzsaFtHSg/oqqrvCKq4W",
   "collapsed_sections": [],
   "name": "AutoEncoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
