{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tnFYDve6LhG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4236,
     "status": "ok",
     "timestamp": 1582532815202,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "ccGi-v_a7_LL",
    "outputId": "496ebb45-e9ec-410d-a890-37f4ee41a1c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4701, 9775)\n",
      "(4230, 3) (2312277, 3)\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('~/Data/clean_rating4.csv').drop([\"id\"], axis = 1)\n",
    "idx_to_users = list(set(ratings['user_id'].tolist()))\n",
    "idx_to_animes = list(set(ratings['anime_id'].tolist()))\n",
    "users_to_idx = {user: idx for idx, user in enumerate(idx_to_users)}\n",
    "animes_to_idx = {anime: idx for idx, anime in enumerate(idx_to_animes)}\n",
    "\n",
    "train_rating_matrix = np.zeros((len(idx_to_users), len(idx_to_animes)))\n",
    "test_rating_matrix = np.zeros((len(idx_to_users), len(idx_to_animes)))\n",
    "train_masks = np.zeros(rating_matrix.shape)\n",
    "test_masks = np.zeros(rating_matrix.shape)\n",
    "\n",
    "print(rating_matrix.shape)\n",
    "\n",
    "train_ratio = 0.9\n",
    "train_data = ratings[:int(len(idx_to_users) * train_ratio)]\n",
    "# train_masks = masks[:int(len(idx_to_users) * train_ratio)]\n",
    "train_user_set = set(train_data.user_id.tolist())\n",
    "test_data = ratings[int(len(idx_to_users) * train_ratio):]\n",
    "# test_masks = masks[int(len(idx_to_users) * train_ratio):]\n",
    "test_user_set = set(test_data.user_id.tolist())\n",
    "\n",
    "for st in train_data.values.tolist():\n",
    "    train_masks[users_to_idx[st[0]], animes_to_idx[st[1]]] = 1\n",
    "    if st[2] == -1:\n",
    "        train_rating_matrix[users_to_idx[st[0]], animes_to_idx[st[1]]] = 5\n",
    "    else:\n",
    "        train_rating_matrix[users_to_idx[st[0]], animes_to_idx[st[1]]] = st[2]\n",
    "\n",
    "for st in test_data.values.tolist():\n",
    "    test_masks[users_to_idx[st[0]], animes_to_idx[st[1]]] = 1\n",
    "    if st[2] == -1:\n",
    "        test_rating_matrix[users_to_idx[st[0]], animes_to_idx[st[1]]] = 5\n",
    "    else:\n",
    "        test_rating_matrix[users_to_idx[st[0]], animes_to_idx[st[1]]] = st[2]\n",
    "        \n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1063,
     "status": "ok",
     "timestamp": 1582534757870,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "CVoLQLiw_8Rn",
    "outputId": "7e88b01a-97f4-4aba-b9b0-b7dfc01173d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (linear1): Linear(in_features=9775, out_features=1500, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (linear2): Linear(in_features=1500, out_features=9775, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, idx_to_users, idx_to_animes, k):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(len(idx_to_animes), k)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(k, len(idx_to_animes))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.sigmoid(self.linear1(input))\n",
    "        return self.linear2(x)\n",
    "\n",
    "net = AutoEncoder(idx_to_users, idx_to_animes, 1500)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "luJRK_AvGYMh"
   },
   "outputs": [],
   "source": [
    "def MyMSELoss(pred, labels, masks, lambda_value, optimizer):\n",
    "        loss = 0\n",
    "        temp = 0\n",
    "        rmse = 0\n",
    "        pred, labels, masks = pred.float(), labels.float(), masks.float()\n",
    "        loss += (((pred - labels) * masks) ** 2).sum()\n",
    "        rmse = loss\n",
    "        \n",
    "        for i in optimizer.param_groups:\n",
    "            for j in i['params']:\n",
    "                if j.data.dim() == 2:\n",
    "                    temp += torch.t(j.data).pow(2).sum()\n",
    "\n",
    "        loss += temp * lambda_value * 0.5\n",
    "\n",
    "        return loss, rmse\n",
    "\n",
    "# loss = MyMSELoss(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKcFjJgItA0j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 9775]) torch.Size([512, 9775]) torch.Size([512, 9775])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "train_dataset = Data.TensorDataset(train_data, train_masks, train_data)\n",
    "data_iter = Data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "for x, y, z in data_iter:\n",
    "    print(x.shape, y.shape, z.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 91182,
     "status": "ok",
     "timestamp": 1582534853599,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "DFZS6He1JlIX",
    "outputId": "3a618acd-33fd-49e5-e556-81f14c3ff7f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on cuda\n",
      "1 4.572679555250528\n",
      "2 2.5429507184868774\n",
      "3 1.7590788801009478\n",
      "4 1.5829841583347506\n",
      "5 1.5366358157027336\n",
      "6 1.5087600988060688\n",
      "7 1.4965009139814134\n",
      "8 1.49090200287554\n",
      "9 1.488489408913928\n",
      "10 1.4865688203610887\n",
      "11 1.484699493702417\n",
      "12 1.4836397549291522\n",
      "13 1.4800017655682058\n",
      "14 1.4761605683361865\n",
      "15 1.4719506932150437\n",
      "16 1.4660852730512952\n",
      "17 1.4593449875666833\n",
      "18 1.4515316802293576\n",
      "19 1.4425823807743308\n",
      "20 1.4330866521099337\n",
      "21 1.4235232735399583\n",
      "22 1.413029793685434\n",
      "23 1.402455643389794\n",
      "24 1.3934379774753793\n",
      "25 1.3818912371167482\n",
      "26 1.3711793004170536\n",
      "27 1.36089797262858\n",
      "28 1.3514935501927166\n",
      "29 1.3418436678445007\n",
      "30 1.3324716151071143\n",
      "31 1.3233664405948742\n",
      "32 1.3151424163660175\n",
      "33 1.3076687737433756\n",
      "34 1.3004587572635544\n",
      "35 1.2937646550102941\n",
      "36 1.2881024540212929\n",
      "37 1.2826793569319672\n",
      "38 1.2757867196360306\n",
      "39 1.2704419880749023\n",
      "40 1.2653502365533715\n",
      "41 1.2611092981461411\n",
      "42 1.2570524089376574\n",
      "43 1.2527679554867588\n",
      "44 1.248386196022587\n",
      "45 1.244071420283447\n",
      "46 1.240590913718744\n",
      "47 1.2356203853539667\n",
      "48 1.2329066771683288\n",
      "49 1.2293135067405658\n",
      "50 1.2257275568666512\n",
      "51 1.2226684368058314\n",
      "52 1.2190469317568684\n",
      "53 1.2148962201834281\n",
      "54 1.2119757499232824\n",
      "55 1.2083997590422284\n",
      "56 1.205748913820413\n",
      "57 1.2021807688621235\n",
      "58 1.198581191381293\n",
      "59 1.195820936809586\n",
      "60 1.1932655854968157\n",
      "61 1.190067794480166\n",
      "62 1.1868197537981244\n",
      "63 1.1837434682583996\n",
      "64 1.181150226241687\n",
      "65 1.1790532092303092\n",
      "66 1.1760961063423394\n",
      "67 1.172275584911303\n",
      "68 1.1696869460708736\n",
      "69 1.1674428076364176\n",
      "70 1.1663192265239362\n",
      "71 1.1622717667231393\n",
      "72 1.1598925480224882\n",
      "73 1.1565251932369536\n",
      "74 1.1535577240744235\n",
      "75 1.1505103302005932\n",
      "76 1.148504979326116\n",
      "77 1.1460112740641122\n",
      "78 1.1441543767010123\n",
      "79 1.1427270267240506\n",
      "80 1.1397749185743176\n",
      "81 1.1386103571191297\n",
      "82 1.1394020516018848\n",
      "83 1.1443660501734656\n",
      "84 1.1346192268183846\n",
      "85 1.131166213992852\n",
      "86 1.1281526803276014\n",
      "87 1.1256469711307406\n",
      "88 1.1233686613983\n",
      "89 1.1211012735383297\n",
      "90 1.1182368984431652\n",
      "91 1.1165357834523308\n",
      "92 1.1149110558648077\n",
      "93 1.1129815014106468\n",
      "94 1.1113875669975457\n",
      "95 1.1090443772192773\n",
      "96 1.1076286105045967\n",
      "97 1.1060189172089114\n",
      "98 1.1037651915564526\n",
      "99 1.1018059842125296\n",
      "100 1.1009944938960463\n"
     ]
    }
   ],
   "source": [
    "def train(net, lr, weight_decay, data_iter, num_epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('train on', device)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum = 0\n",
    "        for X, mask, y in data_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            mask = mask.to(device)\n",
    "            pred = net(X)\n",
    "#             print(mask)\n",
    "            l, rmse = MyMSELoss(pred, y, mask, 1, optimizer)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            l_sum += rmse.item()\n",
    "\n",
    "        l_sum = np.sqrt(l_sum / (masks == 1).sum())\n",
    "        print(epoch + 1, l_sum)\n",
    "\n",
    "train(net, 1e-3, 1e-4, data_iter, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1792,
     "status": "ok",
     "timestamp": 1582534709391,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "Xq8KBxaAPQN7",
    "outputId": "bb7c277f-08b0-4049-9422-fe3afafed435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1074507069999022\n"
     ]
    }
   ],
   "source": [
    "def predict(net, test_data, test_masks):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net = net.to(device)\n",
    "    test_data = test_data.to(device)\n",
    "    test_masks = test_masks.to(device)\n",
    "    pred = net(test_data)\n",
    "    rmse = ((pred - test_data) * test_masks).pow(2).sum()\n",
    "\n",
    "    return np.sqrt(rmse.detach().cpu().numpy() / (test_masks == 1).sum().detach().cpu().numpy())\n",
    "\n",
    "print(predict(net, test_data, test_masks))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNXgzsaFtHSg/oqqrvCKq4W",
   "collapsed_sections": [],
   "name": "AutoEncoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
