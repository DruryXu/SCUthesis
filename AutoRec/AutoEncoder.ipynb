{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tnFYDve6LhG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4236,
     "status": "ok",
     "timestamp": 1582532815202,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "ccGi-v_a7_LL",
    "outputId": "496ebb45-e9ec-410d-a890-37f4ee41a1c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4701, 9775)\n",
      "torch.Size([4701, 9775]) torch.Size([0, 9775])\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('~/Data/clean_rating4.csv').drop([\"id\"], axis = 1)\n",
    "idx_to_users = list(set(ratings['user_id'].tolist()))\n",
    "idx_to_animes = list(set(ratings['anime_id'].tolist()))\n",
    "users_to_idx = {user: idx for idx, user in enumerate(idx_to_users)}\n",
    "animes_to_idx = {anime: idx for idx, anime in enumerate(idx_to_animes)}\n",
    "\n",
    "rating_matrix = np.zeros((len(idx_to_users), len(idx_to_animes)))\n",
    "masks = np.ones(rating_matrix.shape)\n",
    "print(rating_matrix.shape)\n",
    "for st in ratings.values.tolist():\n",
    "    masks[users_to_idx[st[0]], animes_to_idx[st[1]]] = 1\n",
    "    if st[2] == -1:\n",
    "        rating_matrix[users_to_idx[st[0]], animes_to_idx[st[1]]] = 5\n",
    "    else:\n",
    "        rating_matrix[users_to_idx[st[0]], animes_to_idx[st[1]]] = st[2]\n",
    "\n",
    "train_ratio = 1\n",
    "train_data = torch.FloatTensor(rating_matrix[:int(len(idx_to_users) * train_ratio)])\n",
    "train_masks = torch.FloatTensor(masks[:int(len(idx_to_users) * train_ratio)])\n",
    "test_data = torch.FloatTensor(rating_matrix[int(len(idx_to_users) * train_ratio):])\n",
    "test_masks = torch.FloatTensor(masks[int(len(idx_to_users) * train_ratio):])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1063,
     "status": "ok",
     "timestamp": 1582534757870,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "CVoLQLiw_8Rn",
    "outputId": "7e88b01a-97f4-4aba-b9b0-b7dfc01173d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (linear1): Linear(in_features=9775, out_features=1500, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (linear2): Linear(in_features=1500, out_features=9775, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, idx_to_users, idx_to_animes, k):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(len(idx_to_animes), k)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(k, len(idx_to_animes))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.sigmoid(self.linear1(input))\n",
    "        return self.linear2(x)\n",
    "\n",
    "net = AutoEncoder(idx_to_users, idx_to_animes, 1500)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "luJRK_AvGYMh"
   },
   "outputs": [],
   "source": [
    "class MyMSELoss(nn.Module):\n",
    "    def __init__(self, lambda_value):\n",
    "        super(MyMSELoss, self).__init__()\n",
    "        self.lambda_value = lambda_value\n",
    "        \n",
    "        \n",
    "    def forward(self, pred, labels, masks, optimizer):\n",
    "        loss = 0\n",
    "        temp = 0\n",
    "        rmse = 0\n",
    "        pred, labels, masks = pred.float(), labels.float(), masks.float()\n",
    "        loss += ((pred - labels) * masks).pow(2).sum()\n",
    "        rsme = loss\n",
    "\n",
    "        for i in optimizer.param_groups:\n",
    "            for j in i['params']:\n",
    "                if j.data.dim() == 2:\n",
    "                    temp += torch.t(j.data).pow(2).sum()\n",
    "\n",
    "        loss += temp * self.lambda_value * 0.5\n",
    "\n",
    "        return loss, rmse\n",
    "\n",
    "loss = MyMSELoss(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKcFjJgItA0j"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_dataset = Data.TensorDataset(train_data, train_masks, train_data)\n",
    "data_iter = Data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 91182,
     "status": "ok",
     "timestamp": 1582534853599,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "DFZS6He1JlIX",
    "outputId": "3a618acd-33fd-49e5-e556-81f14c3ff7f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on cuda\n",
      "1 0.8734682058693873\n",
      "2 0.8069602860427305\n",
      "3 0.7603997397399992\n",
      "4 0.743341965838138\n",
      "5 0.7354714771915952\n",
      "6 0.7311284090901716\n",
      "7 0.7283299452185846\n",
      "8 0.7263157414186519\n",
      "9 0.7247959874079858\n",
      "10 0.7234033480780035\n",
      "11 0.7221131564069074\n",
      "12 0.7206997241692427\n",
      "13 0.7193017606538412\n",
      "14 0.7178625451431774\n",
      "15 0.7163665253595191\n",
      "16 0.7148358461448077\n",
      "17 0.7132237592673942\n",
      "18 0.7115777712479531\n",
      "19 0.7099387846642613\n",
      "20 0.7084205651297705\n",
      "21 0.7069410605740005\n",
      "22 0.7054573648291345\n",
      "23 0.7040761651213177\n",
      "24 0.7029877405450655\n",
      "25 0.7026136399477375\n",
      "26 0.7018404746121061\n",
      "27 0.6992027468740659\n",
      "28 0.6967219634586107\n",
      "29 0.6953315402836282\n",
      "30 0.6940657722045067\n",
      "31 0.69284709588196\n",
      "32 0.692059781726564\n",
      "33 0.6917837510517728\n",
      "34 0.6914438058647646\n",
      "35 0.6904449593132878\n",
      "36 0.6894104937081508\n",
      "37 0.6890374058248361\n",
      "38 0.6899323165457497\n",
      "39 0.6879076266142123\n",
      "40 0.6866795355065322\n",
      "41 0.6848424916644531\n",
      "42 0.6813004213627456\n",
      "43 0.678480615058632\n",
      "44 0.6763080813735503\n",
      "45 0.6748390653243556\n",
      "46 0.6749375724945886\n",
      "47 0.6792984697299679\n",
      "48 0.6800854929769777\n",
      "49 0.6781975344573351\n",
      "50 0.6756920587033558\n",
      "51 0.6740342350292645\n",
      "52 0.672491244569201\n",
      "53 0.671732189320741\n",
      "54 0.6700971594290044\n",
      "55 0.6688924398230045\n",
      "56 0.6683094937403137\n",
      "57 0.6687931713982226\n",
      "58 0.6686846895209596\n",
      "59 0.6678132367779634\n",
      "60 0.666565775833519\n",
      "61 0.6658470106094581\n",
      "62 0.6677501666670087\n",
      "63 0.6678729784319286\n",
      "64 0.6649034693973008\n",
      "65 0.6647230552844401\n",
      "66 0.664284526207368\n",
      "67 0.6648036646704651\n",
      "68 0.6639733075583536\n",
      "69 0.6657853742271869\n",
      "70 0.66588837648796\n",
      "71 0.6618030696947218\n",
      "72 0.6590920680202347\n",
      "73 0.6576450045432902\n",
      "74 0.6574173324295646\n",
      "75 0.6577806279335274\n",
      "76 0.6576534900970579\n",
      "77 0.656340177512787\n",
      "78 0.6551118976280229\n",
      "79 0.6545998064826847\n",
      "80 0.6552456312630706\n",
      "81 0.6571900160544936\n",
      "82 0.6599516167148644\n",
      "83 0.6590556980134603\n",
      "84 0.6569240181964041\n",
      "85 0.653606265684099\n",
      "86 0.6517626331966488\n",
      "87 0.6501268531494199\n",
      "88 0.6494839820072152\n",
      "89 0.6487230502933576\n",
      "90 0.648627512099673\n",
      "91 0.6495058370733949\n",
      "92 0.6507176335025758\n",
      "93 0.6517940775804457\n",
      "94 0.651462552395588\n",
      "95 0.6509530113619156\n",
      "96 0.651079270431312\n",
      "97 0.6526260290502669\n",
      "98 0.6525781190979261\n",
      "99 0.6503129103582065\n",
      "100 0.649142129303379\n"
     ]
    }
   ],
   "source": [
    "def train(net, lr, weight_decay, data_iter, num_epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('train on', device)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum = 0\n",
    "        for X, mask, y in data_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            mask = mask.to(device)\n",
    "            pred = net(X)\n",
    "            l, rmse = loss(pred, y, mask, optimizer)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            l_sum += l.item()\n",
    "\n",
    "        l_sum = np.sqrt(l_sum / (masks == 1).sum())\n",
    "        print(epoch + 1, l_sum)\n",
    "\n",
    "train(net, 1e-3, 1e-4, data_iter, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1792,
     "status": "ok",
     "timestamp": 1582534709391,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "Xq8KBxaAPQN7",
    "outputId": "bb7c277f-08b0-4049-9422-fe3afafed435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1074507069999022\n"
     ]
    }
   ],
   "source": [
    "def predict(net, test_data, test_masks):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net = net.to(device)\n",
    "    test_data = test_data.to(device)\n",
    "    test_masks = test_masks.to(device)\n",
    "    pred = net(test_data)\n",
    "    rmse = ((pred - test_data) * test_masks).pow(2).sum()\n",
    "\n",
    "    return np.sqrt(rmse.detach().cpu().numpy() / (test_masks == 1).sum().detach().cpu().numpy())\n",
    "\n",
    "print(predict(net, test_data, test_masks))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNXgzsaFtHSg/oqqrvCKq4W",
   "collapsed_sections": [],
   "name": "AutoEncoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
