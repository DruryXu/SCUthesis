{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class item2VecDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, centers, contexts, negatives):\n",
    "        assert len(centers) == len(contexts) == len(negatives)\n",
    "        super(item2VecDataset, self).__init__()\n",
    "        self.centers = centers\n",
    "        self.contexts = contexts\n",
    "        self.negatives = negatives\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.centers[index], self.contexts[index], self.negatives[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryCrossEntropyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, mask = None):\n",
    "        inputs, targets, mask = inputs.float(), targets.float(), mask.float()\n",
    "        res = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction = 'none', weight = mask)\n",
    "        return res.mean(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embedding1 = nn.Embedding(num_embeddings = size, embedding_dim = embed_size)\n",
    "        self.embedding2 = nn.Embedding(num_embeddings = size, embedding_dim = embed_size)\n",
    "\n",
    "    def forward(self, context, center_negative):\n",
    "        v = self.embedding1(context)\n",
    "        v = v.mean(dim = 0)\n",
    "        u = self.embedding2(center_negative)\n",
    "        pred = torch.bmm(v, u.permute(0, 2, 1))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_gram(center, contexts_negatives, embed_v, embed_u):\n",
    "    v = embed_v(center)\n",
    "    u = embed_u(contexts_negatives)\n",
    "    pred = torch.bmm(v, u.permute(0, 2, 1))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_item2Vec(net, lr, num_epochs, loss, data_iter):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('train on', device)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        start, l_sum, n = time.time(), 0.0, 0\n",
    "        for batch in data_iter:\n",
    "            center, context_negative, mask, label = [d.to(device) for d in batch]\n",
    "#            print(center.shape, context_negative.shape)\n",
    "            pred = skip_gram(center, context_negative, net[0], net[1])\n",
    "#            print(pred.shape, mask.shape, label.shape)\n",
    "            l = (loss(pred.view(label.shape), label, mask.view(label.shape)) * mask.shape[1] / mask.float().sum(dim = 1)).mean()\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            l_sum += l.cpu().item()\n",
    "            n += 1\n",
    "\n",
    "        print('epoch %d, loss %f, time %.2fs' % (epoch + 1, l_sum / n, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(path):\n",
    "    ratings = pd.read_csv(path).drop([\"id\"], axis = 1)\n",
    "    positive_rating = ratings[ratings.rating >= 5]\n",
    "    anime_list = positive_rating['anime_id'].tolist() \n",
    "    counter = collections.Counter(anime_list)\n",
    "\n",
    "    idx_to_anime = list(set(anime_list))\n",
    "    anime_to_idx = {anime_id: idx for idx, anime_id in enumerate(idx_to_anime)}\n",
    "    \n",
    "    gp = positive_rating.groupby(\"user_id\")\n",
    "    corpus = [list(map(lambda x: anime_to_idx[x], gp.get_group(user_id)['anime_id'].tolist())) for user_id, _ in gp]\n",
    "    corpus = [[aid for aid in st if subsampling(aid, counter, len(anime_list), idx_to_anime)] for st in corpus]\n",
    "    return corpus, anime_to_idx, idx_to_anime, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling(aid, counter, size, idx_to_anime):\n",
    "    return random.uniform(0, 1) < 1 - math.sqrt(1e-4 * size / counter[idx_to_anime[aid]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_contexts(corpus):\n",
    "    centers, contexts = [], []\n",
    "    for animes in corpus:\n",
    "        if len(animes) < 2:\n",
    "            continue\n",
    "        centers += animes\n",
    "        for idx, _ in enumerate(animes):\n",
    "            contexts.append(animes[:idx] + animes[idx + 1:])\n",
    "\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampling(contexts, weights, K):\n",
    "    negatives, neg_candidates = [], []\n",
    "    all_animes = list(range(len(weights)))\n",
    "    for context in contexts:\n",
    "#        print(contexts.index(context))\n",
    "        negs, i = [], 0\n",
    "        neg_candidates = random.choices(all_animes, weights, k = int(1e5))\n",
    "        while len(negs) < K:\n",
    "            if neg_candidates[i] in context:\n",
    "                i += 1\n",
    "                continue\n",
    "            else:\n",
    "                negs.append(neg_candidates[i])\n",
    "\n",
    "        negatives.append(negs)\n",
    "\n",
    "    return negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_batch(data):\n",
    "    max_len = max([len(context) + len(negative) for _, context, negative in data])\n",
    "    context_negatives, masks, labels, centers = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        context_negatives.append(context + negative + [0] * (max_len - cur_len))\n",
    "        centers.append(center)\n",
    "        masks.append([1] * cur_len + [0] * (max_len - cur_len))\n",
    "        labels.append([1] * len(context) + [0] * (max_len - len(context)))\n",
    "\n",
    "    return (torch.tensor(centers).view(-1, 1), torch.tensor(context_negatives), torch.tensor(masks), torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947294 4701 9255\n",
      "947292 947292\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-34e379cc35bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnegatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-4364bf7d4d7f>\u001b[0m in \u001b[0;36mnegative_sampling\u001b[0;34m(contexts, weights, K)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#        print(contexts.index(context))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mneg_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_animes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mneg_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/random.py\u001b[0m in \u001b[0;36mchoices\u001b[0;34m(self, population, weights, cum_weights, k)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcum_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         return [population[bisect(cum_weights, random() * total, 0, hi)]\n\u001b[0;32m--> 366\u001b[0;31m                 for i in range(k)]\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;31m## -------------------- real-valued distributions  -------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/random.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcum_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         return [population[bisect(cum_weights, random() * total, 0, hi)]\n\u001b[0;32m--> 366\u001b[0;31m                 for i in range(k)]\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;31m## -------------------- real-valued distributions  -------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    anime = pd.read_csv('~/Data/anime.csv')\n",
    "    corpus, anime_to_idx, idx_to_anime, counter = get_corpus('~/Data/clean_rating4.csv')\n",
    "    print(sum([len(st) for st in corpus]), len(corpus), len(idx_to_anime))\n",
    "    \n",
    "    centers, contexts = get_centers_and_contexts(corpus)\n",
    "    weights = [counter[aid] ** 0.75 for aid in idx_to_anime]\n",
    "    print(len(centers), len(contexts))\n",
    "    \n",
    "    negatives = negative_sampling(contexts, weights, 5)\n",
    "    print(len(centers), len(contexts), len(negatives))\n",
    "    \n",
    "    batch_size = 512\n",
    "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\n",
    "    dataset = item2VecDataset(centers, contexts, negatives)\n",
    "    data_iter = Data.DataLoader(dataset, batch_size, shuffle = True, collate_fn = select_batch, num_workers = num_workers)\n",
    "\n",
    "    embed_size = 100\n",
    "#    for batch in data_iter:\n",
    "#        for name, data in zip(['centers', 'context_negatives', 'masks', 'labels'], batch):\n",
    "#            print(name, data.shape)\n",
    "#        break\n",
    "    net = nn.Sequential(\n",
    "        nn.Embedding(num_embeddings = len(idx_to_anime), embedding_dim = embed_size),\n",
    "        nn.Embedding(num_embeddings = len(idx_to_anime), embedding_dim = embed_size) \n",
    "    )\n",
    "    train_item2Vec(net, 0.1, 10, BinaryCrossEntropyLoss(), data_iter)\n",
    "\n",
    "    torch.save(net.state_dict(), 'skip_gram_complete.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param with shape torch.Size([3231, 100]) from checkpoint, the shape in current model is torch.Size([9255, 100]).\n\tsize mismatch for 1.weight: copying a param with shape torch.Size([3231, 100]) from checkpoint, the shape in current model is torch.Size([9255, 100]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fe56407b6759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_to_anime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"skip_gram.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param with shape torch.Size([3231, 100]) from checkpoint, the shape in current model is torch.Size([9255, 100]).\n\tsize mismatch for 1.weight: copying a param with shape torch.Size([3231, 100]) from checkpoint, the shape in current model is torch.Size([9255, 100])."
     ]
    }
   ],
   "source": [
    "embed_size = 100\n",
    "net = nn.Sequential(\n",
    "        nn.Embedding(num_embeddings = len(idx_to_anime), embedding_dim = embed_size),\n",
    "        nn.Embedding(num_embeddings = len(idx_to_anime), embedding_dim = embed_size) \n",
    "    )\n",
    "net.load_state_dict(torch.load(\"skip_gram.pt\"))\n",
    "W = net[0].weight.data\n",
    "x = W[10]\n",
    "print(anime[anime['anime_id'] == 5114])\n",
    "cos = torch.matmul(W, x) / (torch.sum(W * W, dim = 1) * torch.sum(x * x) + 1e-9).sqrt()\n",
    "_, topk = torch.topk(cos, k = 6)\n",
    "topk = topk.cpu().numpy()\n",
    "for i in topk[1:]:\n",
    "    print('cosine sim = %.3f' % (cos[i]))\n",
    "    print(anime[anime['anime_id'] == idx_to_anime[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
