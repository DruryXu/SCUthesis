{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anime_id                              name  \\\n",
      "0     32281                    Kimi no Na wa.   \n",
      "1      5114  Fullmetal Alchemist: Brotherhood   \n",
      "2     28977                          GintamaÂ°   \n",
      "3      9253                       Steins;Gate   \n",
      "4      9969                     Gintama&#039;   \n",
      "\n",
      "                                               genre   type episodes  rating  \\\n",
      "0               Drama, Romance, School, Supernatural  Movie        1    9.37   \n",
      "1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64    9.26   \n",
      "2  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.25   \n",
      "3                                   Sci-Fi, Thriller     TV       24    9.17   \n",
      "4  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.16   \n",
      "\n",
      "   members  \n",
      "0   200630  \n",
      "1   793665  \n",
      "2   114262  \n",
      "3   673572  \n",
      "4   151266  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"~/Data/anime.csv\")\n",
    "print(df.head())\n",
    "data, item_to_genre, genres = df[[\"anime_id\", \"genre\"]].fillna(\"\"), {}, []\n",
    "for st in data.values:\n",
    "    item_to_genre[st[0]] = [a.strip() for a in st[1].split(\",\") if len(a) > 0]\n",
    "    genres += st[1].split(\",\")\n",
    "\n",
    "num_genres = len(set(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv(\"~/Data/clean_rating4.csv\").drop([\"id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['yes', 'yes', 'yes', 'yes', 'no']\n",
      "2\n",
      "['no', 'no', 'no', 'no', 'no']\n",
      "3\n",
      "4\n",
      "['no', 'yes', 'no', 'no', 'no']\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "[[199, 853, 1535, 6746, 431, 1575, 2904, 4898, 5114, 16498], [9253, 6547, 1575, 19815, 2904, 4224, 11757, 1535, 4181, 5114], [9253, 6547, 1575, 19815, 2904, 4224, 11757, 1535, 4181, 5114], [5114, 9253, 6547, 1575, 4181, 2904, 4224, 1535, 16498, 19815], [9253, 6547, 1575, 19815, 2904, 4224, 11757, 1535, 4181, 5114], [9253, 6547, 1575, 19815, 2904, 4224, 11757, 1535, 4181, 5114], [9253, 6547, 1575, 19815, 2904, 4224, 11757, 1535, 4181, 5114], [9253, 6547, 1575, 19815, 2904, 4224, 11757, 1535, 4181, 5114], [9253, 6547, 1575, 19815, 2904, 4224, 11757, 1535, 4181, 5114], [9253, 6547, 1575, 19815, 2904, 4224, 11757, 1535, 4181, 5114]]\n"
     ]
    }
   ],
   "source": [
    "users = list(set(user_item.user_id.tolist()))\n",
    "results, inputs = {}, {}\n",
    "for epoch in range(10):\n",
    "    print(epoch + 1)\n",
    "    test_user = np.random.choice(a = users, size = 1)\n",
    "    user_item = rating_df[rating_df.user_id != test_user[0]]\n",
    "    from collections import defaultdict\n",
    "    grouped, corpus, genre_to_user = user_item.groupby(\"user_id\"), {}, defaultdict(list)\n",
    "    for gp in grouped.groups:\n",
    "        items, sentences = [t[1] for t in grouped.get_group(gp).values if t[2] > 5], []\n",
    "        for item in items:\n",
    "            sentences += item_to_genre.get(item, [])\n",
    "\n",
    "        for genre in set(sentences):\n",
    "            genre_to_user[genre].append(gp)\n",
    "\n",
    "        corpus[gp] = sentences\n",
    "        \n",
    "    sorted_tf_idf, base_genres = tfidf(corpus)\n",
    "    input = get_input(test_user[0], base_genres, item_to_genre, rating_df, df)\n",
    "    \n",
    "    if inputs.get(tuple(input), None):\n",
    "        result = inputs[tuple(input)]\n",
    "    else:\n",
    "        result = recomm(input, corpus, genre_to_user, user_item, sorted_tf_idf)\n",
    "    \n",
    "    results[user] = result\n",
    "    inputs[tuple(input)] = result\n",
    "\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(corpus):\n",
    "    word_frequency, doc_frequency, word_tf, word_idf = defaultdict(int), defaultdict(int), defaultdict(float), defaultdict(float)\n",
    "    for st in corpus.values():\n",
    "        for word in st:\n",
    "            word_frequency[word] += 1\n",
    "        for word in set(st):\n",
    "            doc_frequency[word] += 1\n",
    "\n",
    "    num_words = sum(word_frequency.values())\n",
    "    for word in word_frequency:\n",
    "        word_tf[word] = word_frequency[word] / num_words\n",
    "\n",
    "    for doc in doc_frequency:\n",
    "        word_idf[doc] = math.log(len(corpus) / (doc_frequency[doc] + 1))\n",
    "\n",
    "    tf_idf = {}\n",
    "    for word in word_tf:\n",
    "        tf_idf[word] = word_tf[word] * word_idf[word]\n",
    "    \n",
    "    sorted_tf_idf = sorted(tf_idf.items(), key = lambda x: x[1], reverse = True)\n",
    "    return sorted_tf_idf, [g[0] for g in sorted(tf_idf.items(), key = lambda x: x[1], reverse = True)[:5]]\n",
    "# dic = {'genre': [i[0] for i in sorted_tf_idf], 'tf_idf': [i[1] for i in sorted_tf_idf]}\n",
    "# df = pd.DataFrame(dic)\n",
    "# df.to_csv(\"tf_idf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(user, base_genres, item_to_genre, rating_df, anime_df):\n",
    "    items = [data[1] for data in rating_df[rating_df.user_id == user].values if data[2] == 10]\n",
    "#     print(user)\n",
    "    genres = sum([item_to_genre[i] for i in items], [])\n",
    "#     liked_genres = [g[0] for g in sorted(Counter(genres).items(), key = lambda x: x[1], reverse = True)[:5]]\n",
    "#     print(liked_genres)\n",
    "    result = []\n",
    "    for g in base_genres:\n",
    "        if g in genres:\n",
    "            result.append('yes')\n",
    "        else:\n",
    "            result.append('no')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomm(input, corpus, genre_to_user, user_item, sorted_tf_idf): \n",
    "    print(input)\n",
    "    candidate, all_user = set(corpus.keys()), set(corpus.keys())\n",
    "#     print(candidate)\n",
    "    liked_genres = []\n",
    "    for idx, ans in enumerate(input):\n",
    "        if ans == \"yes\":\n",
    "            candidate &= set(genre_to_user[sorted_tf_idf[idx][0]])\n",
    "            liked_genres.append(sorted_tf_idf[idx][0])\n",
    "        else:\n",
    "            candidate &= all_user - set(genre_to_user[sorted_tf_idf[idx][0]])\n",
    "            \n",
    "#     print(len(candidate))\n",
    "    rec= defaultdict(int)\n",
    "    for user in candidate:\n",
    "        animes = user_item[user_item.user_id == user].anime_id.tolist()\n",
    "        for item in animes:\n",
    "            overlap = set(item_to_genre[item]) & set(liked_genres)\n",
    "            if overlap:\n",
    "                rec[item] += (int(user_item[(user_item.user_id == user) & (user_item.anime_id == item)].rating.values) - 5) * (len(overlap) / len(liked_genres))\n",
    "            else:\n",
    "                rec[item] += (int(user_item[(user_item.user_id == user) & (user_item.anime_id == item)].rating.values) - 5)\n",
    "    return [g[0] for g in sorted(rec.items(), key = lambda x: x[1], reverse = True)[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rec(df):\n",
    "    animes = list(set(df.anime_id))\n",
    "    rec = np.random.choice(animes, 10)\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_items():\n",
    "    animes = pd.read_csv(\"~/Data/anime.csv\")\n",
    "    animes = animes[animes[\"anime_id\"].isin(idx_to_animes)].loc[:, [\"anime_id\", \"rating\", \"members\"]].fillna(0)\n",
    "\n",
    "    scalar = lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    animes[\"rating_norm\"] = animes[[\"rating\"]].apply(scalar)\n",
    "    animes[\"members_norm\"] = animes[[\"members\"]].apply(scalar)\n",
    "    animes[\"weight\"] = 0.6 * animes[\"rating_norm\"] + 0.4 * animes[\"members_norm\"]\n",
    "    animes = animes.sort_values(by = \"weight\", ascending = False)\n",
    "    \n",
    "    return {anime_to_idx[i[0]]: i[1] for i in animes[[\"anime_id\", \"weight\"]].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_hot():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
