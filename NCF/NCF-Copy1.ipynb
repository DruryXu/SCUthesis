{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oKuADFDpu37"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9188,
     "status": "ok",
     "timestamp": 1582782823798,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "EwPQ5D3MqnsE",
    "outputId": "3c9398ee-ec38-4bd1-c2b1-893212844791"
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('~/Data/clean_rating3.csv')\n",
    "\n",
    "idx_to_animes = list(set(ratings['anime_id'].tolist()))\n",
    "idx_to_users = list(set(ratings['user_id'].tolist()))\n",
    "anime_to_idx = {anime: idx for idx, anime in enumerate(idx_to_animes)}\n",
    "user_to_idx = {user: idx for idx, user in enumerate(idx_to_users)}\n",
    "num_users, num_animes = len(idx_to_users), len(idx_to_animes)\n",
    "\n",
    "# train_ratio = 0.9\n",
    "# all_users = list(set(ratings.user_id))\n",
    "# train_sample = random.sample(all_users, int(num_users * train_ratio))\n",
    "# train_data = ratings[ratings.user_id.isin(train_sample)]\n",
    "# test_data = list(set(all_users) - set(train_sample))\n",
    "# print(train_data.shape)\n",
    "\n",
    "data_ps = np.array(ratings.values.tolist())\n",
    "\n",
    "from collections import defaultdict\n",
    "user_item_dic, data, labels = defaultdict(list), [], []\n",
    "for d in data_ps:\n",
    "    user_item_dic[user_to_idx[d[0]]].append(anime_to_idx[d[1]])\n",
    "    data.append([user_to_idx[d[0]], anime_to_idx[d[1]]])\n",
    "    if d[2] != -1:\n",
    "        labels.append(d[2] / 10)\n",
    "    else:\n",
    "        labels.append(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_items():\n",
    "    animes = pd.read_csv(\"~/Data/anime.csv\")\n",
    "    animes = animes[animes[\"anime_id\"].isin(idx_to_animes)].loc[:, [\"anime_id\", \"rating\", \"members\"]].fillna(0)\n",
    "\n",
    "    scalar = lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    animes[\"rating_norm\"] = animes[[\"rating\"]].apply(scalar)\n",
    "    animes[\"members_norm\"] = animes[[\"members\"]].apply(scalar)\n",
    "    animes[\"weight\"] = 0.6 * animes[\"rating_norm\"] + 0.4 * animes[\"members_norm\"]\n",
    "    animes = animes.sort_values(by = \"weight\", ascending = False)\n",
    "    \n",
    "    return [anime_to_idx[i] for i in animes.anime_id.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7k-YI1ajMThk"
   },
   "outputs": [],
   "source": [
    "class NCFDataset(Data.Dataset):\n",
    "    def __init__(self, data, labels, hot_items, user_item_dic):\n",
    "        super(NCFDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.hot_items = hot_items\n",
    "        self.labels = labels\n",
    "        self.dic = user_item_dic\n",
    "        \n",
    "        \n",
    "    def select_ng(self):\n",
    "        ng_sample, users, n = [], set(list(zip(*self.data))[0]), 0\n",
    "#         print(len(users))\n",
    "        for user in users:\n",
    "            for item in self.hot_items:\n",
    "                if item not in self.dic[user]:\n",
    "                    ng_sample.append([user, item])\n",
    "                    n += 1\n",
    "                if n == 10:\n",
    "                    break\n",
    "            n = 0\n",
    "        \n",
    "#         print(len(ng_sample))\n",
    "        self.data += ng_sample\n",
    "        self.labels += [0 for _ in range(len(ng_sample))]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        user, item = self.data[idx][0], self.data[idx][1]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return user, item, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 410, 3323, 4536,  ..., 2820,  392,  668]) tensor([4882,  221, 7783,  ...,   64,  131, 3893])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5120\n",
    "dataset = NCFDataset(data, labels, get_hot_items(), user_item_dic)\n",
    "# dataset.select_ng()\n",
    "data_iter = Data.DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
    "for user, item, label in data_iter:\n",
    "    print(user, item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1582783159809,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "gApTtGldU-Cj",
    "outputId": "d5f04ed0-993d-484f-c25c-fbb3f27d0bf3"
   },
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, model, factor_num = 8, num_layers = 3,\n",
    "               MLP_model = None, GMF_model = None, alpha = 0.5, dropout = 0.5):\n",
    "        super(NCF, self).__init__()\n",
    "        self.MLP_model = MLP_model\n",
    "        self.GMF_model = GMF_model\n",
    "        self.alpha = alpha\n",
    "        self.dropout = dropout\n",
    "        self.user_embed_GMF = nn.Embedding(num_users, factor_num)\n",
    "        self.item_embed_GMF = nn.Embedding(num_items, factor_num)\n",
    "        self.user_embed_MLP = nn.Embedding(num_users, factor_num * (2 ** (num_layers - 1)))\n",
    "        self.item_embed_MLP = nn.Embedding(num_items, factor_num * (2 ** (num_layers - 1)))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Dropout(p = self.dropout),\n",
    "            nn.Linear(factor_num * (2 ** num_layers), factor_num * (2 ** (num_layers - 1))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        for layer in range(num_layers - 1, 0, -1):\n",
    "            self.MLP.add_module('dropout' + str(num_layers - layer), nn.Dropout(p = self.dropout))\n",
    "            self.MLP.add_module('linear' + str(num_layers - layer), nn.Linear(factor_num * (2 ** layer), factor_num * (2 ** (layer - 1))))\n",
    "            self.MLP.add_module('relu' + str(num_layers - layer), nn.ReLU())\n",
    "\n",
    "        self.model = model\n",
    "        if self.model in ['GMF', 'MLP']:\n",
    "            self.NeuMF = nn.Linear(factor_num, 1)\n",
    "        else:\n",
    "            self.NeuMF = nn.Linear(2 * factor_num, 1)\n",
    "\n",
    "        self.__init_weights__()\n",
    "\n",
    "    def __init_weights__(self):\n",
    "        if self.model in ['GMF', 'MLP']:\n",
    "            nn.init.normal_(self.user_embed_GMF.weight, std = 0.01)\n",
    "            nn.init.normal_(self.item_embed_GMF.weight, std = 0.01)\n",
    "            nn.init.normal_(self.user_embed_MLP.weight, std = 0.01)\n",
    "            nn.init.normal_(self.item_embed_MLP.weight, std = 0.01)\n",
    "\n",
    "            for layer in self.MLP:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "#                   nn.init.normal_(layer.weight, std = 0.01)\n",
    "\n",
    "            nn.init.kaiming_uniform_(self.NeuMF.weight, a = 1, nonlinearity = 'sigmoid')\n",
    "#             nn.init.normal_(self.NeuMF.weight, std = 0.01)\n",
    "\n",
    "        elif self.GMF_model and self.MLP_model:\n",
    "            self.user_embed_GMF.weight.data.copy_(self.GMF_model.user_embed_GMF.weight)\n",
    "            self.item_embed_GMF.weight.data.copy_(self.GMF_model.item_embed_GMF.weight)\n",
    "            self.user_embed_MLP.weight.data.copy_(self.MLP_model.user_embed_MLP.weight)\n",
    "            self.item_embed_MLP.weight.data.copy_(self.MLP_model.item_embed_MLP.weight)\n",
    "\n",
    "            for (m1, m2) in zip(self.MLP, self.MLP_model.MLP):\n",
    "                if isinstance(m1, nn.Linear) and isinstance(m2, nn.Linear):\n",
    "                    m1.weight.data.copy_(m2.weight)\n",
    "                    m1.bias.data.copy_(m2.bias)\n",
    "\n",
    "            NeuMF_weight = torch.cat((self.alpha * self.GMF_model.NeuMF.weight, (1 - self.alpha) * self.MLP_model.NeuMF.weight), 1)\n",
    "            NeuMF_bias = self.GMF_model.NeuMF.bias + self.MLP_model.NeuMF.bias\n",
    "\n",
    "            self.NeuMF.weight.data.copy_(NeuMF_weight)\n",
    "            self.NeuMF.bias.data.copy_(NeuMF_bias)\n",
    "            \n",
    "    def forward(self, user, item):\n",
    "        if self.model is 'GMF' or 'NCF':\n",
    "            user_embed_GMF = self.user_embed_GMF(user)\n",
    "            item_embed_GMF = self.item_embed_GMF(item)\n",
    "            \n",
    "#             print(user_embed_GMF.device, item_embed_GMF.decive)\n",
    "            GMF_output = user_embed_GMF * item_embed_GMF\n",
    "\n",
    "        if self.model is 'MLP' or 'NCF':\n",
    "            user_embed_MLP = self.user_embed_MLP(user)\n",
    "            item_embed_MLP = self.item_embed_MLP(item)\n",
    "\n",
    "            MLP_input = torch.cat((user_embed_MLP, item_embed_MLP), 1)\n",
    "            MLP_output = self.MLP(MLP_input)\n",
    "\n",
    "        if self.model is 'NCF':\n",
    "            output = self.NeuMF(torch.cat((MLP_output, GMF_output), 1))\n",
    "        elif self.model is 'MLP':\n",
    "            output = self.NeuMF(MLP_output)\n",
    "        elif self.model is 'GMF':\n",
    "            output = self.NeuMF(GMF_output)\n",
    "            \n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMMtvfYqjBuV"
   },
   "outputs": [],
   "source": [
    "def train(net, num_epochs, lr, train_type = 'NCF'):\n",
    "    print(train_type)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     device = torch.device('cpu')\n",
    "    print('train on', device)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = lr)\n",
    "    loss = nn.MSELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum,n = 0, 0\n",
    "        for user, item, label in data_iter:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            label = label.to(device)\n",
    "            pred = net(user, item)\n",
    "            l = loss(pred.view(label.shape), label.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            l_sum += l.cpu().item()\n",
    "            n += 1\n",
    "\n",
    "        print(epoch + 1, l_sum / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1626318,
     "status": "ok",
     "timestamp": 1582784794369,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "yh7mILPNMtMf",
    "outputId": "46c39d07-b22b-4946-e0d3-ff034778924a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "train on cuda\n",
      "1 0.07472800626265293\n",
      "2 0.03253703837428924\n",
      "3 0.023686092704633215\n",
      "4 0.02076840905213593\n",
      "5 0.019628139603348495\n",
      "6 0.018988240370424115\n",
      "7 0.018557859333869373\n",
      "8 0.018149977011264817\n",
      "9 0.017765081090807388\n",
      "10 0.01745363131626026\n",
      "11 0.01719996008290097\n",
      "12 0.016958638906445986\n",
      "13 0.01677904474583946\n",
      "14 0.016633326716096065\n",
      "15 0.01648558011159268\n",
      "16 0.016370772118896048\n",
      "17 0.016262161043815924\n",
      "18 0.016162908790226013\n",
      "19 0.01610414611656737\n",
      "20 0.01601629818956189\n",
      "21 0.015964674506394015\n",
      "22 0.015916426392646288\n",
      "23 0.01586816767251189\n",
      "24 0.015827903968115516\n",
      "25 0.015791834835744326\n",
      "26 0.015757085652672427\n",
      "27 0.01573451083137039\n",
      "28 0.015709761758365772\n",
      "29 0.015694686324720087\n",
      "30 0.015669607629312847\n",
      "GMF\n",
      "train on cuda\n",
      "1 0.0667820582721407\n",
      "2 0.06217080343999873\n",
      "3 0.0558416335360367\n",
      "4 0.04804970904625541\n",
      "5 0.0400481502922297\n",
      "6 0.03294123825976917\n",
      "7 0.02751655522199393\n",
      "8 0.023837734729248956\n",
      "9 0.021529611401572397\n",
      "10 0.020130422944922583\n",
      "11 0.01926578911099476\n",
      "12 0.018700350626941285\n",
      "13 0.018301269479474223\n",
      "14 0.01799672120404954\n",
      "15 0.017753500002076556\n",
      "16 0.017546875751834307\n",
      "17 0.017368605109568988\n",
      "18 0.017211272387413788\n",
      "19 0.017067264880631407\n",
      "20 0.01693862888789335\n",
      "21 0.016822406314889064\n",
      "22 0.016715117107262676\n",
      "23 0.016617994887084098\n",
      "24 0.016529156635237845\n",
      "25 0.01644821273816737\n",
      "26 0.016375720515337342\n",
      "27 0.016307884411964457\n",
      "28 0.016248956028676324\n",
      "29 0.016195056548806742\n",
      "30 0.01614514347905947\n",
      "NCF\n",
      "train on cuda\n",
      "1 0.10795527723747374\n",
      "2 0.032432257010710425\n",
      "3 0.022937421861698823\n",
      "4 0.020647122983144344\n",
      "5 0.01928348034192658\n",
      "6 0.018239890918069854\n",
      "7 0.01748098007857668\n",
      "8 0.016975568060580204\n",
      "9 0.01658828975529992\n",
      "10 0.016290857156463147\n",
      "11 0.01606352748369868\n",
      "12 0.01587472894695684\n",
      "13 0.015723999583513927\n",
      "14 0.015597447596704197\n",
      "15 0.015485006224191347\n",
      "16 0.015412063395427684\n",
      "17 0.015326336425036257\n",
      "18 0.015250717297969407\n",
      "19 0.015188931746544032\n",
      "20 0.015139511605482096\n",
      "21 0.015092758977863831\n",
      "22 0.015047455977475801\n",
      "23 0.01501453130261327\n",
      "24 0.014981323275427286\n",
      "25 0.014940041822543734\n",
      "26 0.01491677366345134\n",
      "27 0.014893222203432987\n",
      "28 0.014862644173632526\n",
      "29 0.014833743340658562\n",
      "30 0.014815104039792982\n"
     ]
    }
   ],
   "source": [
    "MLP_net = NCF(num_users, num_animes, model = 'MLP')\n",
    "train(MLP_net, 30, lr = 0.0001, train_type = 'MLP')\n",
    "\n",
    "GMF_net = NCF(num_users, num_animes, model = 'GMF')\n",
    "train(GMF_net, 30, lr = 0.0001, train_type = 'GMF')\n",
    "\n",
    "NCF_net = NCF(num_users, num_animes, model = 'NCF', GMF_model = GMF_net, MLP_model = MLP_net)\n",
    "train(NCF_net, 30, lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMTUjG-KlpWT"
   },
   "outputs": [],
   "source": [
    "def metrics(net, test_data):\n",
    "    recall, precise = [], []\n",
    "    for user in test_data:\n",
    "        all_items = torch.LongTensor([i for i in range(num_animes)]).cuda()\n",
    "        test_user = torch.LongTensor([user for i in range(num_animes)]).cuda()\n",
    "        pred = net(test_user, all_items)\n",
    "        _, idx = torch.topk(pred, k = 100, dim = 0)\n",
    "        \n",
    "        target = [anime_to_idx[i] for i in ratings[ratings.user_id == user].anime_id.tolist()]\n",
    "        idx = idx.cpu().numpy().flatten()\n",
    "        overlap = list(set(target) & set(idx))\n",
    "        recall.append(len(overlap) / len(target))\n",
    "        precise.append(len(overlap) / len(idx))\n",
    "        \n",
    "    print(np.mean(recall), np.mean(precise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(NCF_net.state_dict(), \"NCF1.pt\")\n",
    "torch.save(GMF_net.state_dict(), \"GMF1.pt\")\n",
    "torch.save(MLP_net.state_dict(), \"MLP1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03497713525106813 0.1664543524416136\n"
     ]
    }
   ],
   "source": [
    "model = NCF(num_users, num_animes, model = 'NCF', GMF_model = GMF_net, MLP_model = MLP_net).cuda()\n",
    "model.load_state_dict(torch.load(\"NCF.pt\"))\n",
    "metrics(model, test_data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMIrs4udGF4i0DSXmyPQxBf",
   "collapsed_sections": [],
   "name": "NCF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
