{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oKuADFDpu37"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ratings, ratio):\n",
    "    uids, aids = list(set(ratings.user_id.tolist())), list(set(ratings.anime_id.tolist()))\n",
    "    train_data, test_data = [], []\n",
    "    for u in uids:\n",
    "        if not uids.index(u) % 100: print(uids.index(u))\n",
    "        for r in range(1, 11):\n",
    "            temp = ratings[(ratings.user_id == u) & (ratings.rating == r)].values.tolist()\n",
    "            if not temp: \n",
    "                continue\n",
    "            \n",
    "            test_data += temp[int(len(temp) * ratio):]\n",
    "            train_data += temp[:int(len(temp) * ratio)]\n",
    "    \n",
    "    train_data += ratings[ratings.rating == -1].values.tolist()\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9188,
     "status": "ok",
     "timestamp": 1582782823798,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "EwPQ5D3MqnsE",
    "outputId": "3c9398ee-ec38-4bd1-c2b1-893212844791"
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('~/Data/clean_rating4.csv').drop([\"id\"], axis = 1)\n",
    "\n",
    "idx_to_animes = list(set(ratings['anime_id'].tolist()))\n",
    "idx_to_users = list(set(ratings['user_id'].tolist()))\n",
    "anime_to_idx = {anime: idx for idx, anime in enumerate(idx_to_animes)}\n",
    "user_to_idx = {user: idx for idx, user in enumerate(idx_to_users)}\n",
    "num_users, num_animes = len(idx_to_users), len(idx_to_animes)\n",
    "\n",
    "train_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9188,
     "status": "ok",
     "timestamp": 1582782823798,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "EwPQ5D3MqnsE",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3c9398ee-ec38-4bd1-c2b1-893212844791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-909ea047cc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-433001bc37aa>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(ratings, ratio)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mis_other_int_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_other_int_dtype\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfill_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0movalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0mfill_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     \u001b[0mfill_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[1;32m   4343\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4344\u001b[0m             \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4345\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4346\u001b[0m         )\n\u001b[1;32m   4347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   6256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6257\u001b[0m                 new_data = self._data.fillna(\n\u001b[0;32m-> 6258\u001b[0;31m                     \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6259\u001b[0m                 )\n\u001b[1;32m   6260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fillna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_data(ratings, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9188,
     "status": "ok",
     "timestamp": 1582782823798,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "EwPQ5D3MqnsE",
    "outputId": "3c9398ee-ec38-4bd1-c2b1-893212844791"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data, columns = [\"user\", \"anime\", \"rating\"])\n",
    "test_df = pd.DataFrame(test_data, columns = [\"user\", \"anime\", \"rating\"])\n",
    "\n",
    "train_df.to_csv(\"train2.csv\", index = False)\n",
    "test_df.to_csv(\"test2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1636407 680100\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "train_data = pd.read_csv(\"train.csv\").values.tolist()\n",
    "user_item_dic, data_ps_list = defaultdict(list), []\n",
    "for d in train_data:\n",
    "    user_item_dic[user_to_idx[d[0]]].append(anime_to_idx[d[1]])\n",
    "    data_ps_list.append([user_to_idx[d[0]], anime_to_idx[d[1]]])\n",
    "    \n",
    "user_item_dic, data_ps = dict(user_item_dic), data_ps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_items():\n",
    "    animes = pd.read_csv(\"~/Data/anime.csv\")\n",
    "    animes = animes[animes[\"anime_id\"].isin(idx_to_animes)].loc[:, [\"anime_id\", \"rating\", \"members\"]].fillna(0)\n",
    "\n",
    "    scalar = lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    animes[\"rating_norm\"] = animes[[\"rating\"]].apply(scalar)\n",
    "    animes[\"members_norm\"] = animes[[\"members\"]].apply(scalar)\n",
    "    animes[\"weight\"] = 0.6 * animes[\"rating_norm\"] + 0.4 * animes[\"members_norm\"]\n",
    "    animes = animes.sort_values(by = \"weight\", ascending = False)\n",
    "    \n",
    "    return [anime_to_idx[i] for i in animes.anime_id.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7k-YI1ajMThk"
   },
   "outputs": [],
   "source": [
    "class NCFDataset(Data.Dataset):\n",
    "    def __init__(self, data_ps, users, num_items, hot_items, dic, num_ng = 100):\n",
    "        super(NCFDataset, self).__init__()\n",
    "        self.data_ps = data_ps\n",
    "#         self.train_sample = train_sample\n",
    "        self.users = users\n",
    "        self.num_items = num_items\n",
    "        self.num_ng = num_ng\n",
    "        self.hot_items = hot_items\n",
    "        self.dic = dic\n",
    "\n",
    "    def select_ng(self):\n",
    "        self.data_ng, num = [], 0\n",
    "        for u in self.users:\n",
    "            for item in self.hot_items:\n",
    "                if item not in self.dic[u]:\n",
    "                    self.data_ng.append([u, item])\n",
    "                    num += 1\n",
    "                if num == self.num_ng: break\n",
    "            \n",
    "            num = 0\n",
    "                \n",
    "        print(len(self.data_ng))\n",
    "        self.label_ps = [1 for i in range(len(self.data_ps))]\n",
    "        self.label_ng = [0 for i in range(len(self.data_ng))]\n",
    "        self.data = self.data_ps + self.data_ng\n",
    "        self.label = self.label_ps + self.label_ng\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.data[idx][0]\n",
    "        item = self.data[idx][1]\n",
    "        label = self.label[idx]\n",
    "\n",
    "        return user, item, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_ng * len(self.users) + len(self.data_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q4rdKXtv6Sd_",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_data_iter(train_data, batch_size = 5000):\n",
    "    user_inputs, item_inputs, labels = [], [], []\n",
    "    for u in range(len(train_data)):\n",
    "        for i in range(len(train_data[0])):\n",
    "            user_inputs.append(u)\n",
    "            item_inputs.append(i)\n",
    "            labels.append(train_data[u, i])\n",
    "            \n",
    "            if len(user_inputs) == batch_size:\n",
    "                yield torch.LongTensor(user_inputs), torch.LongTensor(item_inputs), torch.LongTensor(labels)\n",
    "            user_inputs, item_inputs, labels = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0fkycKsl7k7",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test_data_iter(test_data):\n",
    "    ng_items, ps_items = [], []\n",
    "    for u in range(len(test_data)):\n",
    "        for i in range(len(test_data[0])):\n",
    "            if test_data[u, i] == 0:\n",
    "                ng_items.append(i)\n",
    "            else:\n",
    "                ps_items.append(i)\n",
    "\n",
    "        yield torch.LongTensor([u for _ in range(len(ng_items))]), torch.LongTensor(ng_items), torch.LongTensor(ps_items)\n",
    "        ng_items, ps_items = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1582783147623,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "fx9x_lVBVOgO",
    "outputId": "9dd2b7b2-069e-4828-97d7-bdaeed34278f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 40960\n",
    "users = [user_to_idx[i] for i in list(set(ratings.user_id.tolist()))]\n",
    "dataset = NCFDataset(data_ps, users, num_animes, get_hot_items(), user_item_dic, num_ng = 100)\n",
    "dataset.select_ng()\n",
    "data_iter = Data.DataLoader(dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1582783159809,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "gApTtGldU-Cj",
    "outputId": "d5f04ed0-993d-484f-c25c-fbb3f27d0bf3"
   },
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, model, factor_num = 8, num_layers = 3,\n",
    "               MLP_model = None, GMF_model = None, alpha = 0.5, dropout = 0.5):\n",
    "        super(NCF, self).__init__()\n",
    "        self.MLP_model = MLP_model\n",
    "        self.GMF_model = GMF_model\n",
    "        self.alpha = alpha\n",
    "        self.dropout = dropout\n",
    "        self.user_embed_GMF = nn.Embedding(num_users, factor_num)\n",
    "        self.item_embed_GMF = nn.Embedding(num_items, factor_num)\n",
    "        self.user_embed_MLP = nn.Embedding(num_users, factor_num * (2 ** (num_layers - 1)))\n",
    "        self.item_embed_MLP = nn.Embedding(num_items, factor_num * (2 ** (num_layers - 1)))\n",
    "\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Dropout(p = self.dropout),\n",
    "            nn.Linear(factor_num * (2 ** num_layers), factor_num * (2 ** (num_layers - 1))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        for layer in range(num_layers - 1, 0, -1):\n",
    "            self.MLP.add_module('dropout' + str(num_layers - layer), nn.Dropout(p = self.dropout))\n",
    "            self.MLP.add_module('linear' + str(num_layers - layer), nn.Linear(factor_num * (2 ** layer), factor_num * (2 ** (layer - 1))))\n",
    "            self.MLP.add_module('relu' + str(num_layers - layer), nn.ReLU())\n",
    "\n",
    "        self.model = model\n",
    "        if self.model in ['GMF', 'MLP']:\n",
    "            self.NeuMF = nn.Linear(factor_num, 1)\n",
    "        else:\n",
    "            self.NeuMF = nn.Linear(2 * factor_num, 1)\n",
    "\n",
    "        self.__init_weights__()\n",
    "\n",
    "    def __init_weights__(self):\n",
    "        if self.model in ['GMF', 'MLP']:\n",
    "            nn.init.normal_(self.user_embed_GMF.weight, std = 0.01)\n",
    "            nn.init.normal_(self.item_embed_GMF.weight, std = 0.01)\n",
    "            nn.init.normal_(self.user_embed_MLP.weight, std = 0.01)\n",
    "            nn.init.normal_(self.item_embed_MLP.weight, std = 0.01)\n",
    "\n",
    "            for layer in self.MLP:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "#                   nn.init.normal_(layer.weight, std = 0.01)\n",
    "\n",
    "            nn.init.kaiming_uniform_(self.NeuMF.weight, a = 1, nonlinearity = 'sigmoid')\n",
    "#             nn.init.normal_(self.NeuMF.weight, std = 0.01)\n",
    "\n",
    "        elif self.GMF_model and self.MLP_model:\n",
    "            self.user_embed_GMF.weight.data.copy_(self.GMF_model.user_embed_GMF.weight)\n",
    "            self.item_embed_GMF.weight.data.copy_(self.GMF_model.item_embed_GMF.weight)\n",
    "            self.user_embed_MLP.weight.data.copy_(self.MLP_model.user_embed_MLP.weight)\n",
    "            self.item_embed_MLP.weight.data.copy_(self.MLP_model.item_embed_MLP.weight)\n",
    "\n",
    "            for (m1, m2) in zip(self.MLP, self.MLP_model.MLP):\n",
    "                if isinstance(m1, nn.Linear) and isinstance(m2, nn.Linear):\n",
    "                    m1.weight.data.copy_(m2.weight)\n",
    "                    m1.bias.data.copy_(m2.bias)\n",
    "\n",
    "            NeuMF_weight = torch.cat((self.alpha * self.GMF_model.NeuMF.weight, (1 - self.alpha) * self.MLP_model.NeuMF.weight), 1)\n",
    "            NeuMF_bias = self.GMF_model.NeuMF.bias + self.MLP_model.NeuMF.bias\n",
    "\n",
    "            self.NeuMF.weight.data.copy_(NeuMF_weight)\n",
    "            self.NeuMF.bias.data.copy_(NeuMF_bias)\n",
    "            \n",
    "    def forward(self, user, item):\n",
    "        if self.model is 'GMF' or 'NCF':\n",
    "            user_embed_GMF = self.user_embed_GMF(user)\n",
    "            item_embed_GMF = self.item_embed_GMF(item)\n",
    "            \n",
    "#             print(user_embed_GMF.device, item_embed_GMF.decive)\n",
    "            GMF_output = user_embed_GMF * item_embed_GMF\n",
    "\n",
    "        if self.model is 'MLP' or 'NCF':\n",
    "            user_embed_MLP = self.user_embed_MLP(user)\n",
    "            item_embed_MLP = self.item_embed_MLP(item)\n",
    "\n",
    "            MLP_input = torch.cat((user_embed_MLP, item_embed_MLP), 1)\n",
    "            MLP_output = self.MLP(MLP_input)\n",
    "\n",
    "        if self.model is 'NCF':\n",
    "            return self.NeuMF(torch.cat((MLP_output, GMF_output), 1))\n",
    "        elif self.model is 'MLP':\n",
    "            return self.NeuMF(MLP_output)\n",
    "        elif self.model is 'GMF':\n",
    "            return self.NeuMF(GMF_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMMtvfYqjBuV"
   },
   "outputs": [],
   "source": [
    "def train(net, num_epochs, lr, train_type = 'NCF'):\n",
    "    print(train_type)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     device = torch.device('cpu')\n",
    "    print('train on', device)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = lr)\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum,n = 0, 0\n",
    "        for user, item, label in data_iter:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            label = label.to(device)\n",
    "            pred = net(user, item)\n",
    "            l = loss(pred.view(label.shape), label.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            l_sum += l.cpu().item()\n",
    "            n += 1\n",
    "\n",
    "        print(epoch + 1, l_sum / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1626318,
     "status": "ok",
     "timestamp": 1582784794369,
     "user": {
      "displayName": "king jeff",
      "photoUrl": "",
      "userId": "00861212005360345850"
     },
     "user_tz": -480
    },
    "id": "yh7mILPNMtMf",
    "outputId": "46c39d07-b22b-4946-e0d3-ff034778924a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "train on cuda\n",
      "1 0.7941221571885623\n",
      "2 0.7726657975178498\n",
      "3 0.75262307203733\n",
      "4 0.7325988973562534\n",
      "5 0.7114335665336022\n",
      "6 0.6886492050611056\n",
      "7 0.6640917349320191\n",
      "8 0.637078093794676\n",
      "9 0.6044462151252307\n",
      "10 0.5655473848948112\n",
      "11 0.5206435872958257\n",
      "12 0.4722450404213025\n",
      "13 0.42488233229288686\n",
      "14 0.38264000415802\n",
      "15 0.3484763944378266\n",
      "16 0.3210383292574149\n",
      "17 0.29993114047325575\n",
      "18 0.28403791097494274\n",
      "19 0.27158835243720275\n",
      "20 0.2622535222998032\n",
      "21 0.25500146786753947\n",
      "22 0.24883958611350793\n",
      "23 0.2439341522180117\n",
      "24 0.23993892939044878\n",
      "25 0.23625643866566512\n",
      "26 0.23328231590298507\n",
      "27 0.2307052698272925\n",
      "28 0.22830236015411523\n",
      "29 0.22627699231872192\n",
      "30 0.2247371063209497\n",
      "GMF\n",
      "train on cuda\n",
      "1 0.7994993409285178\n",
      "2 0.7976299753555884\n",
      "3 0.7957756588092217\n",
      "4 0.7938831872664965\n",
      "5 0.7919075775604981\n",
      "6 0.7896784360592182\n",
      "7 0.7871679388559781\n",
      "8 0.784321013551492\n",
      "9 0.7811374308971258\n",
      "10 0.7776902318000793\n",
      "11 0.7739083709625098\n",
      "12 0.7698091245614566\n",
      "13 0.7654523219053562\n",
      "14 0.7607985115968264\n",
      "15 0.755859279861817\n",
      "16 0.7506334059513532\n",
      "17 0.7451101403969985\n",
      "18 0.7392955823586538\n",
      "19 0.7332069186063913\n",
      "20 0.7268832761507767\n",
      "21 0.7202664327162963\n",
      "22 0.713419972704007\n",
      "23 0.7063015435750668\n",
      "24 0.6989709654679666\n",
      "25 0.6914094881369517\n",
      "26 0.6836207199555177\n",
      "27 0.6756372084984412\n",
      "28 0.6674665636741198\n",
      "29 0.6591334537817881\n",
      "30 0.6506412441913898\n",
      "NCF\n",
      "train on cuda\n",
      "1 4.382968242351826\n",
      "2 3.8131153812775245\n",
      "3 3.3368635590259847\n",
      "4 2.9327937135329614\n",
      "5 2.5851730566758375\n",
      "6 2.2782229368503275\n",
      "7 2.00588897558359\n",
      "8 1.7542061026279743\n",
      "9 1.5108235386701732\n",
      "10 1.26993400316972\n",
      "11 1.050270677759097\n",
      "12 0.8721180088244952\n",
      "13 0.7438712739027463\n",
      "14 0.6516461188976581\n",
      "15 0.5837226922695453\n",
      "16 0.5319196524528357\n",
      "17 0.49245770332904965\n",
      "18 0.46118806818356883\n",
      "19 0.43530671757001144\n",
      "20 0.41475984110282016\n",
      "21 0.3966346996334883\n",
      "22 0.38132034414089644\n",
      "23 0.3690146763737385\n",
      "24 0.35819110388939196\n",
      "25 0.34839148074388504\n",
      "26 0.33921439429888356\n",
      "27 0.3291659767811115\n",
      "28 0.31807892884199435\n",
      "29 0.3082253056076857\n",
      "30 0.30062632663891864\n"
     ]
    }
   ],
   "source": [
    "MLP_net = NCF(num_users, num_animes, model = 'MLP')\n",
    "train(MLP_net, 30, lr = 0.0001, train_type = 'MLP')\n",
    "\n",
    "GMF_net = NCF(num_users, num_animes, model = 'GMF')\n",
    "train(GMF_net, 30, lr = 0.0001, train_type = 'GMF')\n",
    "\n",
    "NCF_net = NCF(num_users, num_animes, model = 'NCF', GMF_model = GMF_net, MLP_model = MLP_net)\n",
    "train(NCF_net, 30, lr = 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(NCF_net.state_dict(), \"NCF2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_net = NCF(num_users, num_animes, model = 'MLP')\n",
    "# train(MLP_net, epochs, lr = 0.0001, train_type = 'MLP')\n",
    "\n",
    "GMF_net = NCF(num_users, num_animes, model = 'GMF')\n",
    "# train(GMF_net, epochs, lr = 0.0001, train_type = 'GMF')\n",
    "\n",
    "\n",
    "model = NCF(num_users, num_animes, model = 'NCF', GMF_model = GMF_net, MLP_model = MLP_net).cuda()\n",
    "model.load_state_dict(torch.load(\"NCF2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test.csv\")\n",
    "users = list(set(df.user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08389704318230165\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"test.csv\")\n",
    "users = list(set(df.user))\n",
    "precise = []\n",
    "for u in users:\n",
    "#     print(u)\n",
    "    all_item = [anime_to_idx[i] for i in df[df.user == u].anime.tolist()]\n",
    "    all_items = torch.LongTensor(all_item).cuda()\n",
    "    test_user = torch.LongTensor([user_to_idx[u] for i in range(len(all_item))]).cuda()\n",
    "    \n",
    "#     print(all_items.shape, test_user.shape)\n",
    "    \n",
    "    pred = NCF_net(test_user, all_items)\n",
    "    pred = pred.view(1, -1).detach().cpu().numpy()[0]\n",
    "    index = [i for i in range(len(pred))]\n",
    "    idx = sorted(dict(zip(pred, index)).items(), key = lambda x: x[0], reverse = True)[:5]\n",
    "    idx = [all_item[d[1]] for d in idx]\n",
    "    \n",
    "        \n",
    "    target = [anime_to_idx[i] for i in df[(df.user == u) & (df.rating > 9)].anime.tolist()]\n",
    "    \n",
    "    \n",
    "    overlap = list(set(target) & set(idx))\n",
    "        \n",
    "    precise.append(len(overlap) / len(idx))\n",
    "#     print(precise[-1])\n",
    "    \n",
    "print(np.mean(precise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(k, ranklist, testlist):\n",
    "    if not testlist: return 0\n",
    "    idcg_k, dcg_k = 0, 0\n",
    "    if len(testlist) < k:\n",
    "        k = len(testlist)\n",
    "    for i in range(k):\n",
    "        idcg_k += 1 / math.log(i + 2, 2)\n",
    "        \n",
    "    s = set(testlist)\n",
    "    hits = [idx for idx, val in enumerate(ranklist) if val in s]\n",
    "    count = len(hits)\n",
    "    \n",
    "    for i in range(count):\n",
    "        dcg_k += 1 / math.log(hits[i] + 2, 2)\n",
    "        \n",
    "    return float(dcg_k / idcg_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG(ratings):\n",
    "    idcg, dcg = 0, 0\n",
    "    for idx, r in enumerate(ratings):\n",
    "        dcg += (2 ** r - 1) / math.log(idx + 2, 2)\n",
    "        \n",
    "#     print(sorted(ratings, reverse = True))\n",
    "    for idx, r in enumerate(sorted(ratings, reverse = True)):\n",
    "        idcg += (2 ** r - 1) / math.log(idx + 2, 2)\n",
    "        \n",
    "    return float(dcg / idcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMTUjG-KlpWT"
   },
   "outputs": [],
   "source": [
    "def metrics(net, df, bound):\n",
    "    precise, ndcg_k = [], []\n",
    "    users = list(set(df.user))\n",
    "    for u in users:\n",
    "        all_item = [anime_to_idx[i] for i in df[df.user == u].anime.tolist()]\n",
    "    #     print(all_item)\n",
    "        all_items = torch.LongTensor(all_item).cuda()\n",
    "        test_user = torch.LongTensor([user_to_idx[u] for i in range(len(all_item))]).cuda()\n",
    "\n",
    "        pred = net(test_user, all_items)\n",
    "\n",
    "        pred = pred.view(1, -1).detach().cpu().numpy()[0]\n",
    "        index = [i for i in range(len(pred))]\n",
    "        idx = sorted(dict(zip(pred, index)).items(), key = lambda x: x[0], reverse = True)[:5]\n",
    "#         idx = [idx_to_animes[all_item[d[1]]] for d in idx]\n",
    "        idx = [all_item[d[1]] for d in idx]\n",
    "\n",
    "        target = [anime_to_idx[i] for i in df[(df.user == u) & (df.rating > bound)].anime.tolist()]\n",
    "        \n",
    "#         rates = [df[(df.user == u) & (df.anime == st)].rating.tolist()[0] for st in idx]\n",
    "#         ndcg_k.append(NDCG(rates))\n",
    "    #     idx = [all_item[i] for i in idx.cpu().numpy().flatten()]\n",
    "        overlap = list(set(target) & set(idx))\n",
    "\n",
    "        precise.append(len(overlap) / len(idx))\n",
    "    #     print(precise[-1])\n",
    "\n",
    "    return np.mean(precise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08410976388002551\n",
      "[0.08410976388002551]\n"
     ]
    }
   ],
   "source": [
    "# model = NCF(num_users, num_animes, model = 'NCF', GMF_model = GMF_net, MLP_model = MLP_net).cuda()\n",
    "# model.load_state_dict(torch.load(\"NCF.pt\"))\n",
    "precise = []\n",
    "for bound in range(9, 10):\n",
    "    precise.append(metrics(NCF_net, df, bound))\n",
    "    print(precise[-1])\n",
    "    \n",
    "print(precise)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMIrs4udGF4i0DSXmyPQxBf",
   "collapsed_sections": [],
   "name": "NCF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
