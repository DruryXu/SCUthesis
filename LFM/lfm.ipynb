{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"~/Data/clean_rating3.csv\")\n",
    "\n",
    "idx_to_user = list(set(data.user_id))\n",
    "idx_to_item = list(set(data[data.rating > 0].anime_id))\n",
    "\n",
    "user_to_idx = {user: idx for idx, user in enumerate(idx_to_user)}\n",
    "item_to_idx = {item: idx for idx, item in enumerate(idx_to_item)}\n",
    "\n",
    "ratings = data[data.rating > 0].rating.values.tolist()\n",
    "data = data[data.rating > 0].values\n",
    "\n",
    "F, alpha, lam_bda, batch_size = 100, 0.02, 0.01, 512000\n",
    "num_epochs, n, k = 30, len(ratings), 1 / math.sqrt(F)\n",
    "\n",
    "P = np.array([[random.random() * k for _ in range(F)] for _ in range(len(idx_to_user))])\n",
    "Q = np.array([[random.random() * k for _ in range(len(idx_to_item))] for _ in range(F)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, alpha, lam_bda):\n",
    "    index = [i for i in range(train_data.shape[0])]\n",
    "    for epoch in range(num_epochs):\n",
    "        sample = random.sample(index, batch_size)\n",
    "        loss = 0\n",
    "        for i in range(batch_size):\n",
    "            user = user_to_idx[train_data[sample[i], 0]]\n",
    "            item = item_to_idx[train_data[sample[i], 1]]\n",
    "            rui = train_data[sample[i], 2]\n",
    "\n",
    "            eui = rui - sigmoid(P[user, :].dot(Q[:, item]))\n",
    "            loss += eui\n",
    "            for f in range(F):\n",
    "                P[user, f] += alpha * (eui * Q[f, item] - lam_bda * P[user, f])\n",
    "                Q[f, item] += alpha * (eui * P[user, f] - lam_bda * Q[f, item])\n",
    "\n",
    "        alpha *= 0.9\n",
    "        print(epoch + 1, loss / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot():\n",
    "    animes = pd.read_csv(\"~/Data/anime.csv\")\n",
    "    animes = animes[animes[\"anime_id\"].isin(idx_to_item)].loc[:, [\"anime_id\", \"rating\", \"members\"]].fillna(0)\n",
    "\n",
    "    scalar = lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    animes[\"rating_norm\"] = animes[[\"rating\"]].apply(scalar)\n",
    "    animes[\"members_norm\"] = animes[[\"members\"]].apply(scalar)\n",
    "    animes[\"weight\"] = 0.6 * animes[\"rating_norm\"] + 0.4 * animes[\"members_norm\"]\n",
    "    animes = animes.sort_values(by = \"weight\", ascending = False)\n",
    "    \n",
    "    return animes.anime_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sample():\n",
    "    sample_num = 100\n",
    "    hot_items, neg_sample = get_hot(), []\n",
    "    data = pd.read_csv(\"~/Data/clean_rating3.csv\")\n",
    "    grouped = data.groupby([\"user_id\"])\n",
    "    for gp in grouped.groups:\n",
    "        p, num = grouped.get_group(gp).anime_id.tolist(), 0\n",
    "        for item in hot_items:\n",
    "            if item not in p: \n",
    "                neg_sample.append([gp, item, 0])\n",
    "                num += 1\n",
    "            if num == sample_num:\n",
    "                break\n",
    "\n",
    "    return np.array(neg_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1875255, 3) (803682, 3)\n"
     ]
    }
   ],
   "source": [
    "data[:, -1] = np.array([1 for _ in range(data.shape[0])])\n",
    "data = np.concatenate((data, negative_sample()))\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data, test_size = 0.3)\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.2115167390094033\n",
      "2 0.12036631683068666\n",
      "3 0.07571939211673791\n",
      "4 0.05596575775700145\n",
      "5 0.04506253217202283\n",
      "6 0.0387128605037591\n",
      "7 0.034222328985989446\n",
      "8 0.0312272810194363\n",
      "9 0.028945453683116896\n",
      "10 0.027167895001621686\n",
      "11 0.025966579931476802\n",
      "12 0.025395539999610056\n",
      "13 0.02404293877463467\n",
      "14 0.023753245461130498\n",
      "15 0.0227208625206945\n",
      "16 0.022629788475069936\n",
      "17 0.02169160439643765\n",
      "18 0.021231997503649364\n",
      "19 0.02188085963464156\n",
      "20 0.020769992658420257\n",
      "21 0.020997924962916564\n",
      "22 0.020094902222702313\n",
      "23 0.02031312734878581\n",
      "24 0.02007480332331186\n",
      "25 0.02058166406107587\n",
      "26 0.019384339155819233\n",
      "27 0.02008436920383563\n",
      "28 0.019597166607862215\n",
      "29 0.020279994353861783\n",
      "30 0.019272585979512667\n"
     ]
    }
   ],
   "source": [
    "train(train_data, alpha, lam_bda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = list(set(test_data[:, 0].tolist()))\n",
    "user_dict, recall, precision = {}, [], []\n",
    "predict = P.dot(Q)\n",
    "for pred in predict:\n",
    "#     pred = P[user_to_idx[user],:].dot(Q).tolist()\n",
    "    dic = {yui: idx for idx, yui in enumerate(pred)}\n",
    "    topk = [i[1] for i in sorted(dic.items(), key = lambda x: x[0], reverse = True)[:10]]\n",
    "    target = [i[1] for i in test_data if i[0] == user]\n",
    "    \n",
    "    both = list(set(topk) & set(target))\n",
    "    recall.append(len(both) / len(topk))\n",
    "    precision.append(len(both) / len(target))\n",
    "    \n",
    "print(recall[0], precision[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
