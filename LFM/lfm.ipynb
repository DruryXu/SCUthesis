{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9775\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"~/Data/clean_rating4.csv\").drop([\"id\"], axis = 1)\n",
    "print(len(set(data.anime_id.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"~/Data/clean_rating4.csv\").drop([\"id\"], axis = 1)\n",
    "\n",
    "idx_to_user = list(set(data.user_id))\n",
    "idx_to_item = list(set(data[data.rating > 0].anime_id))\n",
    "\n",
    "user_to_idx = {user: idx for idx, user in enumerate(idx_to_user)}\n",
    "item_to_idx = {item: idx for idx, item in enumerate(idx_to_item)}\n",
    "\n",
    "ratings = data[data.rating > 0].rating.values.tolist()\n",
    "data = data[data.rating > 0].values\n",
    "\n",
    "F, alpha, lam_bda, batch_size = 100, 0.02, 0.01, 512000\n",
    "num_epochs, n, k = 30, len(ratings), 1 / math.sqrt(F)\n",
    "\n",
    "P = np.array([[random.random() * k for _ in range(F)] for _ in range(len(idx_to_user))])\n",
    "Q = np.array([[random.random() * k for _ in range(len(idx_to_item))] for _ in range(F)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, alpha, lam_bda):\n",
    "    index = [i for i in range(train_data.shape[0])]\n",
    "    for epoch in range(num_epochs):\n",
    "        sample = random.sample(index, batch_size)\n",
    "        loss = 0\n",
    "        for i in range(batch_size):\n",
    "            user = user_to_idx[train_data[sample[i], 0]]\n",
    "            item = item_to_idx[train_data[sample[i], 1]]\n",
    "            rui = train_data[sample[i], 2]\n",
    "\n",
    "            eui = rui - sigmoid(P[user, :].dot(Q[:, item]))\n",
    "            loss += eui\n",
    "            for f in range(F):\n",
    "                P[user, f] += alpha * (eui * Q[f, item] - lam_bda * P[user, f])\n",
    "                Q[f, item] += alpha * (eui * P[user, f] - lam_bda * Q[f, item])\n",
    "\n",
    "        alpha *= 0.9\n",
    "        print(epoch + 1, loss / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot():\n",
    "    animes = pd.read_csv(\"~/Data/anime.csv\")\n",
    "    animes = animes[animes[\"anime_id\"].isin(idx_to_item)].loc[:, [\"anime_id\", \"rating\", \"members\"]].fillna(0)\n",
    "\n",
    "    scalar = lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    animes[\"rating_norm\"] = animes[[\"rating\"]].apply(scalar)\n",
    "    animes[\"members_norm\"] = animes[[\"members\"]].apply(scalar)\n",
    "    animes[\"weight\"] = 0.6 * animes[\"rating_norm\"] + 0.4 * animes[\"members_norm\"]\n",
    "    animes = animes.sort_values(by = \"weight\", ascending = False)\n",
    "    \n",
    "    return animes.anime_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sample():\n",
    "    sample_num = 100\n",
    "    hot_items, neg_sample = get_hot(), []\n",
    "    data = pd.read_csv(\"~/Data/clean_rating4.csv\")\n",
    "    grouped = data.groupby([\"user_id\"])\n",
    "    for gp in grouped.groups:\n",
    "        p, num = grouped.get_group(gp).anime_id.tolist(), 0\n",
    "        for item in hot_items:\n",
    "            if item not in p: \n",
    "                neg_sample.append([gp, item, 0])\n",
    "                num += 1\n",
    "            if num == sample_num:\n",
    "                break\n",
    "\n",
    "    return np.array(neg_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2411043, 3) (267894, 3)\n"
     ]
    }
   ],
   "source": [
    "data[:, -1] = np.array([1 for _ in range(data.shape[0])])\n",
    "data = np.concatenate((data, negative_sample()))\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train_data, test_data = train_test_split(data, test_size = 0.3)\n",
    "train_ratio = 0.9\n",
    "train_data = data[:int(len(data) * train_ratio)]\n",
    "test_data = data[int(len(data) * train_ratio):]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.25555402224789586\n",
      "2 0.11768047158088206\n",
      "3 0.06988390356009232\n",
      "4 0.0498546014280664\n",
      "5 0.03879834465430846\n",
      "6 0.03167170343577947\n",
      "7 0.027983559424568778\n",
      "8 0.024431335325246713\n",
      "9 0.02232596384266356\n",
      "10 0.02123481204885261\n",
      "11 0.02002578105046055\n",
      "12 0.019234978376210916\n",
      "13 0.01869379106775868\n",
      "14 0.019169978291203798\n",
      "15 0.01817782463717157\n",
      "16 0.018633872222880352\n",
      "17 0.018474578669134732\n",
      "18 0.018496947476068393\n",
      "19 0.018218864660697325\n",
      "20 0.018460623520009677\n",
      "21 0.018578304382262517\n",
      "22 0.01836879926304485\n",
      "23 0.01828924723231968\n",
      "24 0.01841833640908466\n",
      "25 0.018320572018831725\n",
      "26 0.018399330378176468\n",
      "27 0.018195561897799313\n",
      "28 0.018011473451270743\n",
      "29 0.017993123198943622\n",
      "30 0.017682960586546777\n"
     ]
    }
   ],
   "source": [
    "train(train_data, alpha, lam_bda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006414840402932892\n",
      "0.0006424496614325545\n",
      "0.0006432293297745433\n",
      "0.0006449825033630561\n",
      "0.0006459255643350805\n",
      "0.0006468108600326396\n",
      "0.0006446370329482179\n",
      "0.0006388234745975467\n",
      "0.0006284423305507102\n",
      "0.0006109836720050726\n"
     ]
    }
   ],
   "source": [
    "test_users = list(set(test_data[:, 0].tolist()))\n",
    "df = pd.read_csv(\"~/Data/clean_rating4.csv\").drop([\"id\"], axis = 1)\n",
    "user_dict, final, precision = {}, [], []\n",
    "recall, f1 = [], []\n",
    "predict = P.dot(Q)\n",
    "for k in range(10):\n",
    "    for user in test_users:\n",
    "        user_idx = user_to_idx[user]\n",
    "        pred = predict[user_idx, :]\n",
    "        dic = {yui: idx for idx, yui in enumerate(pred)}\n",
    "        topk = [i[1] for i in sorted(dic.items(), key = lambda x: x[0], reverse = True)[1:6]]\n",
    "        target = [data[1] for data in df[df.user_id == user].values if data[2] > k]\n",
    "        \n",
    "#         print(topk, target)\n",
    "        both = list(set(topk) & set(target))\n",
    "        if not both:\n",
    "            f1.append(0)\n",
    "            continue\n",
    "        precision.append(len(both) / len(topk))\n",
    "        recall.append(len(both) / len(target))\n",
    "        f1.append((2 * recall[-1] * precision[-1]) / (recall[-1] + precision[-1]))\n",
    "\n",
    "    print(np.mean(f1))\n",
    "    final.append(np.mean(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04088397790055249, 0.04077348066298343, 0.0407182320441989, 0.04055248618784531, 0.04022099447513812, 0.03968692449355433, 0.038587213891081294, 0.036505524861878455, 0.03378759975445058, 0.03087292817679558]\n"
     ]
    }
   ],
   "source": [
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal expression for augmented assignment (<ipython-input-2-b5e5c79f0a1a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b5e5c79f0a1a>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    a, b, c += 1,1, 1\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal expression for augmented assignment\n"
     ]
    }
   ],
   "source": [
    "a, b, c = 0, 0, 0\n",
    "\n",
    "print(a, b, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
